import streamlit as st
import requests
import base64
import re
import json
from datetime import datetime, date
from PIL import Image
from io import BytesIO
import pandas as pd
from difflib import SequenceMatcher

# ------------------------------
# 1. é¡µé¢é…ç½®
# ------------------------------
st.set_page_config(page_title="è®ºæ–‡æ‰“å¡æ ¸éªŒç³»ç»Ÿ", layout="wide")
st.title("ğŸ“š ç¤¾ç¾¤è®ºæ–‡æ‰“å¡ Â· è‡ªåŠ¨æ ¸éªŒä¸æ’è¡Œæ¦œ")

# ------------------------------
# 2. ä» secrets è¯»å–å¯†é’¥ï¼ˆå·²åœ¨ GitHub/Streamlit è®¾ç½®ï¼‰
# ------------------------------
BAIDU_API_KEY = st.secrets["BAIDU_API_KEY"]
BAIDU_SECRET_KEY = st.secrets["BAIDU_SECRET_KEY"]
FEISHU_APP_ID = st.secrets["FEISHU_APP_ID"]
FEISHU_APP_SECRET = st.secrets["FEISHU_APP_SECRET"]
FEISHU_APP_TOKEN = st.secrets["FEISHU_APP_TOKEN"]
FEISHU_TABLE_ID = st.secrets["FEISHU_TABLE_ID"]
FEISHU_MEMBER_TABLE_ID = st.secrets.get("FEISHU_MEMBER_TABLE_ID", None)  # å¯é€‰

# ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.75 è¡¨ç¤º75%ç›¸ä¼¼å³é€šè¿‡ï¼‰
THRESHOLD = 0.75

# ------------------------------
# 3. ç™¾åº¦OCRè·å–access_token
# ------------------------------
def get_baidu_access_token():
    url = "https://aip.baidubce.com/oauth/2.0/token"
    params = {
        "grant_type": "client_credentials",
        "client_id": BAIDU_API_KEY,
        "client_secret": BAIDU_SECRET_KEY
    }
    res = requests.post(url, params=params)
    return res.json().get("access_token")

# ------------------------------
# 4. è°ƒç”¨ç™¾åº¦é€šç”¨æ–‡å­—è¯†åˆ«ï¼ˆæ ‡å‡†ç‰ˆï¼‰
# ------------------------------
def baidu_ocr(image_bytes):
    token = get_baidu_access_token()
    url = f"https://aip.baidubce.com/rest/2.0/ocr/v1/general_basic?access_token={token}"
    headers = {"Content-Type": "application/x-www-form-urlencoded"}
    img_base64 = base64.b64encode(image_bytes).decode()
    data = {"image": img_base64}
    resp = requests.post(url, headers=headers, data=data)
    result = resp.json()
    if "words_result" in result:
        return [item["words"] for item in result["words_result"]]
    else:
        st.error(f"OCRè¯†åˆ«å¤±è´¥ï¼š{result}")
        return []

# ------------------------------
# 5. ä»é£ä¹¦å¤šç»´è¡¨æ ¼è·å–ä»Šæ—¥è®ºæ–‡æ‘˜è¦
# ------------------------------
def get_feishu_access_token():
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
    headers = {"Content-Type": "application/json; charset=utf-8"}
    payload = {
        "app_id": FEISHU_APP_ID,
        "app_secret": FEISHU_APP_SECRET
    }
    res = requests.post(url, headers=headers, json=payload)
    return res.json().get("tenant_access_token")

def fetch_today_abstract():
    token = get_feishu_access_token()
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json; charset=utf-8"
    }
    # ç­›é€‰ï¼šå‘å¸ƒæ—¥æœŸ = ä»Šå¤©
    today_str = date.today().strftime("%Y-%m-%d")
    # æ³¨æ„ï¼šé£ä¹¦å¤šç»´è¡¨æ ¼æ—¥æœŸå­—æ®µè¿‡æ»¤è¯­æ³•ä¸º 'å­—æ®µå = "å€¼"'
    # è¿™é‡Œç®€å•æŸ¥è¯¢å‰10æ¡ï¼Œå–å‘å¸ƒæ—¥æœŸåŒ¹é…ä»Šå¤©çš„ï¼›è‹¥æ²¡æœ‰åˆ™å–æœ€æ–°ä¸€æ¡
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{FEISHU_APP_TOKEN}/tables/{FEISHU_TABLE_ID}/records"
    params = {"page_size": 10}
    resp = requests.get(url, headers=headers, params=params)
    records = resp.json().get("data", {}).get("items", [])
    
    for rec in records:
        fields = rec.get("fields", {})
        pub_date = fields.get("å‘å¸ƒæ—¥æœŸ")
        if pub_date:
            # é£ä¹¦è¿”å›æ—¥æœŸæ ¼å¼å¯èƒ½ä¸º "2026-02-13"
            if pub_date.startswith(today_str):
                abstract = fields.get("è®ºæ–‡æ‘˜è¦", "")
                return abstract.strip()
    # æ²¡æ‰¾åˆ°å½“å¤©çš„ï¼Œå–ç¬¬ä¸€æ¡ï¼ˆå‡è®¾ç®¡ç†å‘˜å·²å½•å…¥ï¼‰
    if records:
        fields = records[0].get("fields", {})
        return fields.get("è®ºæ–‡æ‘˜è¦", "").strip()
    return ""

# ------------------------------
# 6. ä»OCRæ–‡æœ¬ä¸­è§£ææ‰“å¡ä¿¡æ¯ï¼ˆé€‚é…ä½ çš„å°çº¢ä¹¦æ¨¡ç‰ˆï¼‰
# ------------------------------
def parse_checkin(text_lines):
    """
    è¾“å…¥ï¼šOCRè¯†åˆ«çš„æ–‡æœ¬è¡Œåˆ—è¡¨
    è¾“å‡ºï¼šåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (æ˜µç§°, æ‰“å¡æ—¶é—´, æ‘˜å½•å¥å­)
    """
    entries = []
    i = 0
    while i < len(text_lines):
        line = text_lines[i].strip()
        # åŒ¹é…æ˜µç§°è¡Œï¼šæ ¼å¼å¦‚ "æ˜µç§°ï¼ˆä»…ä¸­æ–‡/è‹±æ–‡/æ•°å­—ä¸”æœ€å¥½ä¸è¦é‡åï¼‰ï¼šå¼ ä¸‰"
        nick_match = re.match(r'^æ˜µç§°.*?[:ï¼š]\s*(.*?)$', line)
        if nick_match:
            nickname = nick_match.group(1).strip()
            # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦æ˜¯æ‰“å¡æ—¶é—´
            if i+1 < len(text_lines):
                time_line = text_lines[i+1].strip()
                time_match = re.match(r'^æ‰“å¡æ—¶é—´.*?[:ï¼š]\s*(\d{4}/\d{1,2}/\d{1,2})', time_line)
                if time_match:
                    punch_time = time_match.group(1).strip()
                    # å†ä¸‹ä¸€è¡Œæ˜¯æ‘˜è¦å¥å­
                    if i+2 < len(text_lines):
                        abstract_line = text_lines[i+2].strip()
                        # å»é™¤å¯èƒ½çš„å‰ç¼€
                        abstract_sentence = re.sub(r'^è®ºæ–‡(åŸæ–‡)?æ‘˜è¦çš„éšæœºä¸€å¥è¯.*?[:ï¼š]', '', abstract_line).strip()
                        entries.append((nickname, punch_time, abstract_sentence))
                        i += 3
                        continue
        i += 1
    return entries

# ------------------------------
# 7. ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆç®€å•æ–‡æœ¬åŒ¹é…ï¼‰
# ------------------------------
def similarity(a, b):
    return SequenceMatcher(None, a, b).ratio()

# ------------------------------
# 8. ä»é£ä¹¦è·å–æˆå‘˜æ˜µç§°åˆ—è¡¨ï¼ˆç”¨äºæ¨¡ç³ŠåŒ¹é…ï¼‰
# ------------------------------
def fetch_member_nicknames():
    if not FEISHU_MEMBER_TABLE_ID:
        return []
    token = get_feishu_access_token()
    headers = {"Authorization": f"Bearer {token}"}
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{FEISHU_APP_TOKEN}/tables/{FEISHU_MEMBER_TABLE_ID}/records"
    resp = requests.get(url, headers=headers)
    records = resp.json().get("data", {}).get("items", [])
    nicknames = []
    for rec in records:
        fields = rec.get("fields", {})
        nick = fields.get("æ˜µç§°", "")
        if nick:
            nicknames.append(nick.strip())
    return nicknames

# ------------------------------
# 9. ä¼šè¯çŠ¶æ€åˆå§‹åŒ–ï¼ˆå­˜å‚¨æ‰“å¡è®°å½•ï¼‰
# ------------------------------
if "records" not in st.session_state:
    st.session_state.records = []  # æ¯æ¡ä¸º (æ˜µç§°, æ‰“å¡æ—¥æœŸ, æ‘˜è¦, æ˜¯å¦é€šè¿‡, ç›¸ä¼¼åº¦)
if "pending_review" not in st.session_state:
    st.session_state.pending_review = []  # å¾…å¤æ ¸ï¼ˆç›¸ä¼¼åº¦ä½äºé˜ˆå€¼æˆ–æ˜µç§°ä¸åŒ¹é…ï¼‰

# ------------------------------
# 10. ä¸»ç•Œé¢ï¼šä¸Šä¼ ä¸æ ¸éªŒ
# ------------------------------
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ğŸ“¤ ä¸Šä¼ æ‰“å¡æˆªå›¾")
    uploaded_files = st.file_uploader("æ”¯æŒPNG/JPGï¼Œå¯å¤šé€‰ï¼ˆé•¿æˆªå›¾å»ºè®®æ‹†åˆ†ä¸ºå•äººæˆ–ç›´æ¥ä¸Šä¼ æ•´å¼ ï¼‰",
                                      type=["png", "jpg", "jpeg"],
                                      accept_multiple_files=True)
    
    if uploaded_files:
        # è·å–å½“æ—¥æ ‡å‡†æ‘˜è¦
        standard_abstract = fetch_today_abstract()
        if not standard_abstract:
            st.warning("âš ï¸ ä»Šæ—¥è®ºæ–‡æ‘˜è¦æœªå½•å…¥é£ä¹¦å¤šç»´è¡¨æ ¼ï¼Œè¯·ç®¡ç†å‘˜è¡¥å½•ã€‚")
        else:
            st.info(f"ğŸ“„ ä»Šæ—¥è®ºæ–‡æ‘˜è¦ï¼ˆå‰100å­—ï¼‰ï¼š{standard_abstract[:100]}...")
        
        member_nicknames = fetch_member_nicknames()
        
        for uploaded_file in uploaded_files:
            # è¯»å–å›¾ç‰‡å­—èŠ‚
            image_bytes = uploaded_file.read()
            # OCRè¯†åˆ«
            with st.spinner(f"æ­£åœ¨è¯†åˆ« {uploaded_file.name} ..."):
                text_lines = baidu_ocr(image_bytes)
            
            if not text_lines:
                st.error(f"{uploaded_file.name} è¯†åˆ«å¤±è´¥ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡æ˜¯å¦æ¸…æ™°ã€‚")
                continue
            
            # è§£ææ‰“å¡æ¡ç›®
            entries = parse_checkin(text_lines)
            if not entries:
                st.warning(f"{uploaded_file.name} æœªæ£€æµ‹åˆ°ç¬¦åˆæ ¼å¼çš„æ‰“å¡ä¿¡æ¯ï¼Œè¯·ç¡®è®¤æˆªå›¾åŒ…å«ä¸‰è¡Œè§„èŒƒæ–‡æœ¬ã€‚")
                continue
            
            st.success(f"{uploaded_file.name} å…±è¯†åˆ«å‡º {len(entries)} æ¡æ‰“å¡è®°å½•")
            
            # é€æ¡å¤„ç†
            for nickname, punch_time, sentence in entries:
                # æ—¥æœŸæœ‰æ•ˆæ€§ï¼šå¿…é¡»æ˜¯ä»Šå¤©ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
                is_date_valid = (punch_time == date.today().strftime("%Y/%m/%d"))
                
                # ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆå¦‚æœæ ‡å‡†æ‘˜è¦å­˜åœ¨ï¼‰
                if standard_abstract:
                    sim = similarity(sentence, standard_abstract)
                    is_sim_pass = sim >= THRESHOLD
                else:
                    sim = 0.0
                    is_sim_pass = False
                
                # æ˜µç§°æœ‰æ•ˆæ€§ï¼šè‹¥é…ç½®äº†æˆå‘˜è¡¨ï¼Œæ£€æŸ¥æ˜¯å¦åœ¨è¡¨ä¸­
                nick_valid = True
                if member_nicknames:
                    # ç®€å•åŒ…å«åŒ¹é…ï¼ˆå¯æ”¹ä¸ºæ¨¡ç³ŠåŒ¹é…ï¼‰
                    if not any(nickname in m or m in nickname for m in member_nicknames):
                        nick_valid = False
                
                # æ•´ä½“æ˜¯å¦é€šè¿‡ï¼ˆæ—¥æœŸå¿…é¡»ä»Šå¤©ï¼Œç›¸ä¼¼åº¦å¿…é¡»è¾¾æ ‡ï¼‰
                passed = is_date_valid and is_sim_pass and nick_valid
                
                # è®°å½•
                record = {
                    "æ˜µç§°": nickname,
                    "æ‰“å¡æ—¥æœŸ": punch_time,
                    "æ‘˜å½•å¥å­": sentence,
                    "ç›¸ä¼¼åº¦": round(sim, 2),
                    "æ—¥æœŸæœ‰æ•ˆ": is_date_valid,
                    "ç›¸ä¼¼åº¦è¾¾æ ‡": is_sim_pass,
                    "æ˜µç§°æœ‰æ•ˆ": nick_valid,
                    "é€šè¿‡": passed
                }
                st.session_state.records.append(record)
                
                if not passed:
                    st.session_state.pending_review.append(record)
            
            # æ˜¾ç¤ºæœ¬æ¬¡è¯†åˆ«ç»“æœ
            df_temp = pd.DataFrame(entries, columns=["æ˜µç§°", "æ‰“å¡æ—¶é—´", "æ‘˜å½•å¥å­"])
            st.dataframe(df_temp, use_container_width=True)

# ------------------------------
# 11. å¾…å¤æ ¸é¢æ¿ï¼ˆç®¡ç†å‘˜æ‰‹åŠ¨ä¿®æ­£ï¼‰
# ------------------------------
with col2:
    st.subheader("ğŸ›  å¾…å¤æ ¸æ¡ç›®")
    if st.session_state.pending_review:
        review_df = pd.DataFrame(st.session_state.pending_review)
        st.dataframe(review_df)
        
        # ç®€å•ä¿®æ­£ï¼šä¸€é”®å¼ºåˆ¶é€šè¿‡ï¼ˆå®é™…å¯è®¾è®¡ä¸‹æ‹‰é€‰æ‹©ï¼‰
        if st.button("å°†é€‰ä¸­çš„æ¡ç›®å¼ºåˆ¶æ ‡è®°ä¸ºé€šè¿‡"):
            # ç®€åŒ–ï¼šå…¨éƒ¨å¼ºåˆ¶é€šè¿‡ï¼ˆæ­£å¼ç¯å¢ƒå¯åŠ äº¤äº’ï¼‰
            for rec in st.session_state.pending_review:
                rec["é€šè¿‡"] = True
            st.session_state.pending_review.clear()
            st.success("å·²å¼ºåˆ¶é€šè¿‡æ‰€æœ‰å¾…å¤æ ¸æ¡ç›®ï¼Œè¯·åˆ·æ–°é¡µé¢æŸ¥çœ‹æ’è¡Œæ¦œã€‚")
            st.experimental_rerun()
    else:
        st.info("å½“å‰æ— å¾…å¤æ ¸æ¡ç›®")

# ------------------------------
# 12. æ‰“å¡æ’è¡Œæ¦œï¼ˆæ—¥/å‘¨/æœˆï¼‰
# ------------------------------
st.markdown("---")
st.subheader("ğŸ† æ‰“å¡æ’è¡Œæ¦œ")

if st.session_state.records:
    df = pd.DataFrame(st.session_state.records)
    # ä»…ç»Ÿè®¡é€šè¿‡çš„æœ‰æ•ˆæ‰“å¡
    valid_df = df[df["é€šè¿‡"] == True]
    
    if not valid_df.empty:
        # æŒ‰æ˜µç§°åˆ†ç»„è®¡æ•°
        rank = valid_df.groupby("æ˜µç§°").size().reset_index(name="æ‰“å¡æ¬¡æ•°")
        rank = rank.sort_values("æ‰“å¡æ¬¡æ•°", ascending=False).reset_index(drop=True)
        
        col_a, col_b = st.columns(2)
        with col_a:
            st.write("ğŸ“Š ç´¯è®¡æ‰“å¡æ¬¡æ•°æ¦œ")
            st.dataframe(rank, use_container_width=True)
            
            # ç®€å•å›¾è¡¨
            st.bar_chart(rank.set_index("æ˜µç§°")["æ‰“å¡æ¬¡æ•°"])
        
        with col_b:
            # æŒ‰æ—¥æœŸç­›é€‰
            st.write("ğŸ“… æŒ‰æ—¥æœŸæŸ¥çœ‹")
            date_options = valid_df["æ‰“å¡æ—¥æœŸ"].unique()
            selected_date = st.selectbox("é€‰æ‹©æ—¥æœŸ", sorted(date_options, reverse=True))
            daily_df = valid_df[valid_df["æ‰“å¡æ—¥æœŸ"] == selected_date]
            daily_rank = daily_df.groupby("æ˜µç§°").size().reset_index(name="å½“æ—¥æ‰“å¡æ¬¡æ•°")
            daily_rank = daily_rank.sort_values("å½“æ—¥æ‰“å¡æ¬¡æ•°", ascending=False)
            st.dataframe(daily_rank, use_container_width=True)
    else:
        st.info("æš‚æ— æœ‰æ•ˆæ‰“å¡è®°å½•")
else:
    st.info("æš‚æ— æ‰“å¡è®°å½•ï¼Œè¯·ä¸Šä¼ æˆªå›¾")

# ------------------------------
# 13. ç®¡ç†å‘˜å·¥å…·ï¼ˆæ‘˜è¦å½•å…¥æé†’ã€å¯¼å‡ºè®°å½•ï¼‰
# ------------------------------
with st.expander("ğŸ”§ ç®¡ç†å‘˜å·¥å…·"):
    st.write("å½“å‰å­˜å‚¨çš„æ‰“å¡è®°å½•æ¡æ•°ï¼š", len(st.session_state.records))
    if st.button("æ¸…ç©ºå½“å‰æ‰€æœ‰è®°å½•ï¼ˆæ…ç”¨ï¼‰"):
        st.session_state.records = []
        st.session_state.pending_review = []
        st.success("å·²æ¸…ç©º")
        st.experimental_rerun()
    
    # å¯¼å‡ºä¸ºCSV
    if st.session_state.records:
        export_df = pd.DataFrame(st.session_state.records)
        csv = export_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ å¯¼å‡ºå…¨éƒ¨è®°å½•ä¸ºCSV", csv, "punch_records.csv", "text/csv")
    
    st.caption("ğŸ’¡ æ¯æ—¥è¯·ç¡®ä¿é£ä¹¦å¤šç»´è¡¨æ ¼ä¸­å·²å½•å…¥å½“å¤©è®ºæ–‡æ‘˜è¦ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ‹‰å–ã€‚")
